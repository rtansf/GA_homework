Problem Description and Solution
--------------------------------

A classification model takes a set of input variables (also called features) and outputs a class label for
that set of input variables. A supervised classification model means that apriori, we have a dataset 
with known class labels for a given set of features. In order to minimize prediction errors for the class
label on out-of-sample data, we use this dataset to train the classification model.

The steps for training the model are:

1. Split the dataset into training set and a test set.
   We do this to prevent "overfitting" the model. If we took the entire dataset as our training dataset,
   we would have 0 training errors but the model will not generalize well to out-of-sample data. 
   The goal is to minimize the generalization error and ultimately to miminize out-of-sample errors.

2. Fitting the model by associating the training set class labels with the training set input variables.

3. Let the model predict the class labels for the test set tuples and scoring the model by the accuracy
   of the prediction. This score is a measure of the generalization error. A higher score indicates a
   lower generalization error.  

Just simply splitting the dataset once into a training set and test set will not necessarily yield the 
minimum generalization error. Since there can be several permutations in which we can split a dataset,
each permutation will yield a different score. Hence we could repeat steps 1 - 3 for each permutation
and take the average score at the end as an estimate of out-of-sample accuracy.

The process above is called k-fold cross validation, where n = the number of folds. One fold is used
for the test data and the remaining folds as training data. Cross validation ensures that we minimize
generalization errors and maximize the accuracy of prediction class labels on out-of-sample data.
 
We could also apply cross validation on several different models and choose the model that gives us the 
best score. Hence it is a good way to perform model selection.

When working with especially large datasets, there can be a tradeoff between efficiency and computational
expense. A 100-fold cross validation is 100x more computationally expensive than a single train/test 
split. In any case, the number of folds to use must not exceed the size of the dataset.   

The xvalidate program, runs an k-fold cross-validation using different models on the Iris Dataset 
from sklearn. The current models supported are KNN and Naive-Bayes. Perhaps we will add more models in 
the future. It takes the model as a parameter and a mininum k-fold and maximum k-fold and iterates over
each k-fold to generate the average score for that k-fold. At the end, the k-fold with the highest
accuracy is printed.

In future, xvalidate could be enhanced to take as arguments, a list of k-fold values
instead of a min an max k-fold value. Instead of printing the results, it could return them as a tuple.
 

How to run xvalidate
--------------------

For example, to run cross-validation, using KNN classifier, using k-folds from 2 to 40, enter the 
following:

./xvalidate -c KNN -minf 2 -maxf 40

Outputs:
Using classifier: KNN
fold <<2>> :: average accuracy score <<0.313333333333>>
fold <<3>> :: average accuracy score <<0.0>>
fold <<4>> :: average accuracy score <<0.8856685633>>
fold <<5>> :: average accuracy score <<0.906666666667>>
fold <<6>> :: average accuracy score <<0.92>>
fold <<7>> :: average accuracy score <<0.952380952381>>
fold <<8>> :: average accuracy score <<0.953216374269>>
fold <<9>> :: average accuracy score <<0.952614379085>>
fold <<10>> :: average accuracy score <<0.946666666667>>
fold <<11>> :: average accuracy score <<0.95954045954>>
fold <<12>> :: average accuracy score <<0.959401709402>>
fold <<13>> :: average accuracy score <<0.95979020979>>
fold <<14>> :: average accuracy score <<0.953246753247>>
fold <<15>> :: average accuracy score <<0.96>>
fold <<16>> :: average accuracy score <<0.958333333333>>
fold <<17>> :: average accuracy score <<0.959967320261>>
fold <<18>> :: average accuracy score <<0.958333333333>>
fold <<19>> :: average accuracy score <<0.960526315789>>
fold <<20>> :: average accuracy score <<0.958928571429>>
fold <<21>> :: average accuracy score <<0.959183673469>>
fold <<22>> :: average accuracy score <<0.959956709957>>
fold <<23>> :: average accuracy score <<0.959627329193>>
fold <<24>> :: average accuracy score <<0.958333333333>>
fold <<25>> :: average accuracy score <<0.96>>
fold <<26>> :: average accuracy score <<0.960256410256>>
fold <<27>> :: average accuracy score <<0.959259259259>>
fold <<28>> :: average accuracy score <<0.957142857143>>
fold <<29>> :: average accuracy score <<0.958620689655>>
fold <<30>> :: average accuracy score <<0.96>>
fold <<31>> :: average accuracy score <<0.959677419355>>
fold <<32>> :: average accuracy score <<0.959375>>
fold <<33>> :: average accuracy score <<0.959090909091>>
fold <<34>> :: average accuracy score <<0.955882352941>>
fold <<35>> :: average accuracy score <<0.957142857143>>
fold <<36>> :: average accuracy score <<0.958333333333>>
fold <<37>> :: average accuracy score <<0.959459459459>>
fold <<38>> :: average accuracy score <<0.960526315789>>
fold <<39>> :: average accuracy score <<0.959401709402>>
Highest Accuracy: fold <<19>> :: <<0.960526315789>>

For example, to run cross-validation, using Naive-Bayes classifier, using k-folds from 2 to 40, enter 
the following:

./xvalidate -c Naive-Bayes -minf 2 -maxf 40

Outputs:
Using classifier: Naive-Bayes
fold <<2>> :: average accuracy score <<0.306666666667>>
fold <<3>> :: average accuracy score <<0.0>>
fold <<4>> :: average accuracy score <<0.926386913229>>
fold <<5>> :: average accuracy score <<0.946666666667>>
fold <<6>> :: average accuracy score <<0.933333333333>>
fold <<7>> :: average accuracy score <<0.9329004329>>
fold <<8>> :: average accuracy score <<0.939692982456>>
fold <<9>> :: average accuracy score <<0.946078431373>>
fold <<10>> :: average accuracy score <<0.946666666667>>
fold <<11>> :: average accuracy score <<0.946053946054>>
fold <<12>> :: average accuracy score <<0.952991452991>>
fold <<13>> :: average accuracy score <<0.946386946387>>
fold <<14>> :: average accuracy score <<0.946103896104>>
fold <<15>> :: average accuracy score <<0.953333333333>>
fold <<16>> :: average accuracy score <<0.952083333333>>
fold <<17>> :: average accuracy score <<0.952614379085>>
fold <<18>> :: average accuracy score <<0.952160493827>>
fold <<19>> :: average accuracy score <<0.953947368421>>
fold <<20>> :: average accuracy score <<0.952678571429>>
fold <<21>> :: average accuracy score <<0.952380952381>>
fold <<22>> :: average accuracy score <<0.952380952381>>
fold <<23>> :: average accuracy score <<0.952380952381>>
fold <<24>> :: average accuracy score <<0.951388888889>>
fold <<25>> :: average accuracy score <<0.953333333333>>
fold <<26>> :: average accuracy score <<0.952564102564>>
fold <<27>> :: average accuracy score <<0.951851851852>>
fold <<28>> :: average accuracy score <<0.95119047619>>
fold <<29>> :: average accuracy score <<0.951724137931>>
fold <<30>> :: average accuracy score <<0.953333333333>>
fold <<31>> :: average accuracy score <<0.951612903226>>
fold <<32>> :: average accuracy score <<0.9515625>>
fold <<33>> :: average accuracy score <<0.951515151515>>
fold <<34>> :: average accuracy score <<0.95>>
fold <<35>> :: average accuracy score <<0.95>>
fold <<36>> :: average accuracy score <<0.951388888889>>
fold <<37>> :: average accuracy score <<0.952702702703>>
fold <<38>> :: average accuracy score <<0.953947368421>>
fold <<39>> :: average accuracy score <<0.950854700855>>
Highest Accuracy: fold <<19>> :: <<0.953947368421>>

From the above results, it seems that KNN is slightly better than Naive-Bayes in overall prediction 
accuracy.